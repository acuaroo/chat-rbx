{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LayerNormalization, MultiHeadAttention, Dropout, GlobalAveragePooling1D, Input\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    13761.000000\n",
      "mean         3.640433\n",
      "std          2.278675\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          3.000000\n",
      "75%          5.000000\n",
      "max         18.000000\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# import the data, display histogram of the length of the sentences\n",
    "data = pd.read_csv('clean-data/clean-3-10-23.csv', header=None)\n",
    "data = data.iloc[:, 0]\n",
    "\n",
    "data.str.split().apply(len).hist(bins=20)\n",
    "plt.show()\n",
    "print(data.str.split().apply(len).describe())\n",
    "\n",
    "data = data.str.split().apply(lambda x: x).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['Open', 'lane!', 'Check', 'chat', 'logs', 'kick', 'her', 'fen', 'Some', 'lady']\n"
     ]
    }
   ],
   "source": [
    "tokens = data.tolist()\n",
    "tokens = list(itertools.chain.from_iterable(data))\n",
    "\n",
    "print(type(tokens))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open lane! Check chat logs\n",
      "lane! Check chat logs kick\n",
      "Check chat logs kick her\n",
      "chat logs kick her fen\n"
     ]
    }
   ],
   "source": [
    "given_words = 4\n",
    "guess_words = 1\n",
    "\n",
    "training_length = given_words + guess_words\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(training_length, len(tokens)):\n",
    "    seq = tokens[i-training_length:i]\n",
    "    text_sequences.append(seq)\n",
    "\n",
    "for i in range(given_words):\n",
    "    print(' '.join(text_sequences[i]))\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences)\n",
    "\n",
    "# print(len(sequences[66]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 6371\n",
      "1 --> you\n",
      "2 --> to\n",
      "3 --> i\n",
      "4 --> me\n",
      "5 --> the\n",
      "6 --> fan\n",
      "7 --> donate\n",
      "8 --> u\n",
      "9 --> can\n",
      "10 --> my\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "vocabulary_size = len(tokenizer.word_counts) + 1\n",
    "print(f\"vocab size: {vocabulary_size}\")\n",
    "\n",
    "for a in tokenizer.index_word:\n",
    "    print(a, \"-->\", tokenizer.index_word[a])\n",
    "    i += 1\n",
    "\n",
    "    if i == 10: break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50091, 5)\n"
     ]
    }
   ],
   "source": [
    "sequences = np.array(sequences)\n",
    "print(sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50091, 4) (50091, 6371)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "train_data = sequences[:, :-guess_words]\n",
    "train_labels = sequences[:, -guess_words]\n",
    "\n",
    "randomize = np.arange(len(train_data))\n",
    "np.random.shuffle(randomize)\n",
    "\n",
    "train_data = train_data[randomize]\n",
    "train_labels = train_labels[randomize]\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=vocabulary_size)\n",
    "\n",
    "print(train_data.shape, train_labels.shape)\n",
    "\n",
    "sequence_len = train_data.shape[1]\n",
    "print(sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "class Transformer(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\"), Dense(embed_dim),]\n",
    "        )\n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_and_position_embeddin  (None, 4, 25)            159375    \n",
      " g (TokenAndPositionEmbeddin                                     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " transformer (Transformer)   (None, 4, 25)             65800     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 25)             0         \n",
      "                                                                 \n",
      " transformer_1 (Transformer)  (None, 4, 25)            27175     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4, 25)             0         \n",
      "                                                                 \n",
      " transformer_2 (Transformer)  (None, 4, 25)            14300     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 25)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 25)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 500)               13000     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6371)              3191871   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,471,521\n",
      "Trainable params: 3,471,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=(sequence_len,)))\n",
    "\n",
    "model.add(TokenAndPositionEmbedding(sequence_len, vocabulary_size, 25))\n",
    "\n",
    "model.add(Transformer(25, 25, 25))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Transformer(25, 10, 25))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Transformer(25, 5, 25))\n",
    "\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(500, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(vocabulary_size, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "392/392 [==============================] - 15s 25ms/step - loss: 6.9574 - accuracy: 0.0275\n",
      "Epoch 2/25\n",
      "392/392 [==============================] - 8s 19ms/step - loss: 6.7813 - accuracy: 0.0283\n",
      "Epoch 3/25\n",
      "392/392 [==============================] - 8s 20ms/step - loss: 6.7095 - accuracy: 0.0296\n",
      "Epoch 4/25\n",
      "392/392 [==============================] - 7s 19ms/step - loss: 6.6357 - accuracy: 0.0318\n",
      "Epoch 5/25\n",
      "392/392 [==============================] - 9s 24ms/step - loss: 6.5696 - accuracy: 0.0323\n",
      "Epoch 6/25\n",
      "392/392 [==============================] - 9s 24ms/step - loss: 6.5029 - accuracy: 0.0354\n",
      "Epoch 7/25\n",
      "392/392 [==============================] - 9s 24ms/step - loss: 6.4439 - accuracy: 0.0374\n",
      "Epoch 8/25\n",
      "392/392 [==============================] - 8s 19ms/step - loss: 6.3837 - accuracy: 0.0412\n",
      "Epoch 9/25\n",
      "392/392 [==============================] - 8s 20ms/step - loss: 6.3300 - accuracy: 0.0451\n",
      "Epoch 10/25\n",
      "392/392 [==============================] - 9s 24ms/step - loss: 6.2793 - accuracy: 0.0485\n",
      "Epoch 11/25\n",
      "392/392 [==============================] - 11s 28ms/step - loss: 6.2313 - accuracy: 0.0532\n",
      "Epoch 12/25\n",
      "392/392 [==============================] - 8s 20ms/step - loss: 6.1889 - accuracy: 0.0563\n",
      "Epoch 13/25\n",
      "392/392 [==============================] - 8s 20ms/step - loss: 6.1535 - accuracy: 0.0594\n",
      "Epoch 14/25\n",
      "392/392 [==============================] - 8s 20ms/step - loss: 6.1177 - accuracy: 0.0617\n",
      "Epoch 15/25\n",
      "392/392 [==============================] - 8s 20ms/step - loss: 6.0885 - accuracy: 0.0617\n",
      "Epoch 16/25\n",
      "392/392 [==============================] - 8s 19ms/step - loss: 6.0608 - accuracy: 0.0640\n",
      "Epoch 17/25\n",
      "392/392 [==============================] - 8s 19ms/step - loss: 6.0335 - accuracy: 0.0643\n",
      "Epoch 18/25\n",
      "392/392 [==============================] - 8s 19ms/step - loss: 6.0057 - accuracy: 0.0662\n",
      "Epoch 19/25\n",
      "392/392 [==============================] - 8s 20ms/step - loss: 5.9719 - accuracy: 0.0675\n",
      "Epoch 20/25\n",
      "392/392 [==============================] - 8s 19ms/step - loss: 5.9394 - accuracy: 0.0694\n",
      "Epoch 21/25\n",
      "392/392 [==============================] - 8s 19ms/step - loss: 5.9137 - accuracy: 0.0699\n",
      "Epoch 22/25\n",
      "392/392 [==============================] - 8s 20ms/step - loss: 5.8864 - accuracy: 0.0716\n",
      "Epoch 23/25\n",
      "392/392 [==============================] - 8s 20ms/step - loss: 5.8654 - accuracy: 0.0730\n",
      "Epoch 24/25\n",
      "392/392 [==============================] - 8s 20ms/step - loss: 5.8338 - accuracy: 0.0750\n",
      "Epoch 25/25\n",
      "392/392 [==============================] - 8s 20ms/step - loss: 5.8091 - accuracy: 0.0757\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    history = model.fit(\n",
    "        train_data, train_labels, batch_size=128, epochs=25\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    output_text = []\n",
    "    \n",
    "    input_text = seed_text\n",
    "    \n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        \n",
    "        predict_x = model.predict(pad_encoded, verbose=0) \n",
    "        pred_word_ind = np.argmax(predict_x, axis=1)[0]\n",
    "\n",
    "        pred_word = tokenizer.index_word[pred_word_ind] \n",
    "        \n",
    "        input_text += ' ' + pred_word\n",
    "        \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you look liked you\u001b[91m fan i donate me i\u001b[00m\n",
      "------- generated text -------\n",
      "fan i donate me i\n"
     ]
    }
   ],
   "source": [
    "text = 'you look liked you'\n",
    "\n",
    "new_text = generate_text(model, tokenizer, sequence_len, seed_text=text, num_gen_words=5)\n",
    "\n",
    "print(f\"{text}\\033[91m {new_text}\\033[00m\")\n",
    "\n",
    "print(\"------- generated text -------\")\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i really like that\u001b[91m i donate me i donate\u001b[00m\n",
      "i donate me i donate\u001b[91m me i donate me i\u001b[00m\n",
      "me i donate me i\u001b[91m donate me i donate me\u001b[00m\n",
      "donate me i donate me\u001b[91m i donate me i donate\u001b[00m\n",
      "i donate me i donate\u001b[91m me i donate me i\u001b[00m\n",
      "me i donate me i\u001b[91m donate me i donate me\u001b[00m\n",
      "donate me i donate me\u001b[91m i donate me i donate\u001b[00m\n",
      "i donate me i donate\u001b[91m me i donate me i\u001b[00m\n",
      "me i donate me i\u001b[91m donate me i donate me\u001b[00m\n",
      "donate me i donate me\u001b[91m i donate me i donate\u001b[00m\n",
      "i donate me i donate\u001b[91m me i donate me i\u001b[00m\n",
      "me i donate me i\u001b[91m donate me i donate me\u001b[00m\n",
      "donate me i donate me\u001b[91m i donate me i donate\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "previous_text = 'i really like that'\n",
    "\n",
    "for i in range(15):\n",
    "    gen_text = generate_text(model, tokenizer, sequence_len, seed_text=previous_text, num_gen_words=5)\n",
    "\n",
    "    print(f\"{previous_text}\\033[91m {gen_text}\\033[00m\")\n",
    "    previous_text = gen_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
